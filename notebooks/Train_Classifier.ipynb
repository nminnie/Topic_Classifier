{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw27Vd_NXxOp",
        "colab_type": "text"
      },
      "source": [
        "# Setting up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLl3EzmY6zWu",
        "colab_type": "code",
        "outputId": "77eae0a8-ed92-4a79-a22b-7e12aec3a323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zroopZmr70VA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pickle\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EODWSWl9HHz",
        "colab_type": "text"
      },
      "source": [
        "## Data Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3_YLjq_7wRa",
        "colab_type": "code",
        "outputId": "9d4fe2c5-3e45-40d2-8ff5-4f6e9cd29fef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My\\ Drive/Colab\\ Notebooks"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhOg6ZYBXa1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from data_cleaning import clean_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjnbOjvPXrXN",
        "colab_type": "text"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbGtpDBdX0R4",
        "colab_type": "code",
        "outputId": "6de38074-3f1a-4c7a-d73c-25bf09bdb83e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My\\ Drive/Colab\\ Notebooks/data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcgaQ4KB8KPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = [], []\n",
        "with open(\"reviews_8_categories.txt\", \"r\") as file:\n",
        "    for line in file:\n",
        "        label, text = line.split(\"\\t\")\n",
        "        text = clean_text(text)\n",
        "        X_train.append(text)\n",
        "        y_train.append(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUU2QXSHX5Yh",
        "colab_type": "text"
      },
      "source": [
        "## Define Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4LCTKTKBgfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Linear Support Vector Classifier \n",
        "linear_SVC_BoW = Pipeline([(\"vec\", CountVectorizer()), (\"clf\", LinearSVC())])\n",
        "linear_SVC_tfidf = Pipeline([(\"vec\", TfidfVectorizer()), (\"clf\", LinearSVC())])\n",
        "\n",
        "# Naive Bayes\n",
        "naive_bayes_BoW = Pipeline([(\"vec\", CountVectorizer()), (\"clf\", MultinomialNB())])\n",
        "naive_bayes_tfidf = Pipeline([(\"vec\", TfidfVectorizer()), (\"clf\", MultinomialNB())])\n",
        "\n",
        "# k-Nearest Neighbors\n",
        "kNN_BoW = Pipeline([(\"vec\", CountVectorizer()), (\"clf\", KNeighborsClassifier(weights='distance'))])\n",
        "kNN_tfidf = Pipeline([(\"vec\", TfidfVectorizer()), (\"clf\", KNeighborsClassifier(weights='distance'))])\n",
        "\n",
        "# Logistic Regression\n",
        "log_reg_BoW = Pipeline([(\"vec\", CountVectorizer()), (\"clf\", LogisticRegression(solver='lbfgs', multi_class='auto'))])\n",
        "log_reg_tfidf = Pipeline([(\"vec\", TfidfVectorizer()), (\"clf\", LogisticRegression(solver='lbfgs', multi_class='auto'))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YADzyIrL3m4J",
        "colab_type": "text"
      },
      "source": [
        "## Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ct3Qo4MMYfN",
        "colab_type": "code",
        "outputId": "dfbfd963-4f7f-46f5-d847-0a7378e546bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# Construct a dictionary for all the models above\n",
        "all_models = {\n",
        "    'Naive Bayes BoW': naive_bayes_BoW, 'Naive Bayes TFIDF': naive_bayes_tfidf, \n",
        "    'Logistic Reg BoW': log_reg_BoW, 'Logistic Reg TFIDF': log_reg_tfidf, \n",
        "    'LinearSVC BoW': linear_SVC_BoW, 'LinearSVC TFIDF': linear_SVC_tfidf,\n",
        "    'kNN BoW': kNN_BoW, 'kNN TFIDF': kNN_tfidf\n",
        "}\n",
        "\n",
        "# Perform cross validation for each model\n",
        "cv_scores = [(name, cross_val_score(model, X_train, y_train, cv=4, scoring='accuracy', n_jobs=-1, verbose=1).mean()) for name, model in all_models.items()]\n",
        "sorted_scores = sorted(cv_scores, key=lambda x: -x[1], reverse=True)\n",
        "\n",
        "# Print the accuracy score per model, from lowest to highest\n",
        "for score in sorted_scores:\n",
        "    print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   18.7s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   18.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  1.5min finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  1.5min finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  1.1min finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   26.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  3.3min finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "('kNN TFIDF', 0.20732499999999998)\n",
            "('kNN BoW', 0.463025)\n",
            "('Naive Bayes TFIDF', 0.8186)\n",
            "('Naive Bayes BoW', 0.836375)\n",
            "('LinearSVC BoW', 0.847925)\n",
            "('Logistic Reg BoW', 0.85385)\n",
            "('Logistic Reg TFIDF', 0.8634375000000001)\n",
            "('LinearSVC TFIDF', 0.87085)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  3.3min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr8GpL4wy7YF",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRpOw7ERMPWd",
        "colab_type": "code",
        "outputId": "a7a6b833-4586-451d-8736-4a86f6b2e5aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Define values for Logistic Regression hyperparameters\n",
        "params_log_reg = {\n",
        "    'vec__min_df': [1, 0.0001, 0.0005],\n",
        "    'vec__max_df': [0.75, 0.85, 1.0],\n",
        "    'clf__C':  [0.1, 1, 10, 50]\n",
        "}\n",
        "\n",
        "gsearch_log_reg = GridSearchCV(log_reg_tfidf, params_log_reg, cv=4, n_jobs=-1, verbose=1, scoring='accuracy', return_train_score=True)\n",
        "gsearch_log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Store the best Logistic Regression model for stacking later\n",
        "log_reg_tuned = gsearch_log_reg.best_estimator_\n",
        "log_reg_score = gsearch_log_reg.best_score_\n",
        "\n",
        "print(\"Best score: {}\\nBest params: {}\".format(log_reg_score, gsearch_log_reg.best_params_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 14.5min\n",
            "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed: 43.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.8663125\n",
            "Best params: {'clf__C': 10, 'vec__max_df': 0.75, 'vec__min_df': 0.0001}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVzVR1mROjmV",
        "colab_type": "code",
        "outputId": "00ed3d92-b7bc-4e6e-a61b-9d76e5ae1b49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Define values for Naive Bayes hyperparameters\n",
        "params_naive_bayes = {\n",
        "    'vec__ngram_range': [(1, 1), (1, 2)],\n",
        "    'vec__max_df': [0.7, 0.8, 1.0],\n",
        "    'vec__min_df': [1, 0.0001, 0.0005],\n",
        "}\n",
        "\n",
        "gsearch_naive_bayes = GridSearchCV(naive_bayes_tfidf, params_naive_bayes, cv=4, n_jobs=-1, verbose=1, scoring='accuracy', return_train_score=True)\n",
        "gsearch_naive_bayes.fit(X_train, y_train)\n",
        "\n",
        "# Store the best Naive Bayes model for stacking later\n",
        "naive_bayes_tuned = gsearch_naive_bayes.best_estimator_\n",
        "naive_bayes_score = gsearch_naive_bayes.best_score_\n",
        "\n",
        "print(\"Best score: {}\\nBest params: {}\".format(naive_bayes_score, gsearch_naive_bayes.best_params_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  9.9min\n",
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed: 15.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.855925\n",
            "Best params: {'vec__max_df': 0.7, 'vec__min_df': 0.0001, 'vec__ngram_range': (1, 1)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97wXhpJB38Dp",
        "colab_type": "code",
        "outputId": "878c2228-49d3-4736-bcc5-d74b3d129a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Define values for Linear SVC hyperparameters\n",
        "params_linear_SVC = {\n",
        "    'vec__max_df': [0.75, 0.85, 1.0],\n",
        "    'clf__dual': [True, False],\n",
        "    'clf__C': [0.1, 1, 10]\n",
        "}\n",
        "\n",
        "gsearch_linear_SVC = GridSearchCV(linear_SVC_tfidf, params_linear_SVC, cv=4, n_jobs=-1, verbose=1, scoring='accuracy', return_train_score=True)\n",
        "gsearch_linear_SVC.fit(X_train, y_train)\n",
        "\n",
        "linear_SVC_score = gsearch_linear_SVC.best_score_\n",
        "linear_SVC_tuned = gsearch_linear_SVC.best_estimator_\n",
        "\n",
        "print(\"Best score: {}\\nBest params: {}\".format(linear_SVC_score, gsearch_linear_SVC.best_params_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  8.2min\n",
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed: 15.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.8708625000000001\n",
            "Best params: {'clf__C': 1, 'clf__dual': True, 'vec__max_df': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CnC07FFFq3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(log_reg_tuned, open('LR_model.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9kDsDKnPH2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = pickle.load(open('LR_model.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}